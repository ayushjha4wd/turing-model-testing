{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Write a code to implement federated learning in Python using the Flower framework to train a model across multiple clients while ensuring data privacy.  Create dummy dataset"
      ],
      "metadata": {
        "id": "AKn_3pXvig2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flwr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTKfKg2siw9f",
        "outputId": "63f28622-f1e0-4cff-b924-ed56963ede99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flwr\n",
            "  Downloading flwr-1.10.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: cryptography<43.0.0,>=42.0.4 in /usr/local/lib/python3.10/dist-packages (from flwr) (42.0.8)\n",
            "Requirement already satisfied: grpcio!=1.64.2,!=1.65.1,<2.0.0,>=1.60.0 in /usr/local/lib/python3.10/dist-packages (from flwr) (1.64.1)\n",
            "Collecting iterators<0.0.3,>=0.0.2 (from flwr)\n",
            "  Downloading iterators-0.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr) (1.25.2)\n",
            "Collecting pathspec<0.13.0,>=0.12.1 (from flwr)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting protobuf<5.0.0,>=4.25.2 (from flwr)\n",
            "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting pycryptodome<4.0.0,>=3.18.0 (from flwr)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from flwr) (2.0.1)\n",
            "Collecting tomli-w<2.0.0,>=1.0.0 (from flwr)\n",
            "  Downloading tomli_w-1.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting typer<0.10.0,>=0.9.0 (from typer[all]<0.10.0,>=0.9.0->flwr)\n",
            "  Downloading typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<43.0.0,>=42.0.4->flwr) (1.16.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.9.0->typer[all]<0.10.0,>=0.9.0->flwr) (8.1.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.9.0->typer[all]<0.10.0,>=0.9.0->flwr) (4.12.2)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<0.10.0,>=0.9.0->flwr)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.10.0,>=0.9.0->flwr) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.10.0,>=0.9.0->flwr) (13.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<43.0.0,>=42.0.4->flwr) (2.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->flwr) (0.1.2)\n",
            "Downloading flwr-1.10.0-py3-none-any.whl (421 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iterators-0.0.2-py3-none-any.whl (3.9 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.0.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading typer-0.9.4-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: typer, tomli-w, pycryptodome, protobuf, pathspec, iterators, colorama, flwr\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.12.3\n",
            "    Uninstalling typer-0.12.3:\n",
            "      Successfully uninstalled typer-0.12.3\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 flwr-1.10.0 iterators-0.0.2 pathspec-0.12.1 protobuf-4.25.4 pycryptodome-3.20.0 tomli-w-1.0.0 typer-0.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "15I4ya1Yiu9c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZSgL_0giQXd",
        "outputId": "1bb5358d-7bc5-4798-ac57-b513b75036a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-10 (start_server):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-4-fa427e760366>\", line 64, in start_server\n",
            "TypeError: start_server() got an unexpected keyword argument 'stop_event'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting server...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-11 (start_client):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-4-fa427e760366>\", line 73, in start_client\n",
            "TypeError: start_numpy_client() got an unexpected keyword argument 'stop_event'\n",
            "Exception in thread Thread-12 (start_client):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "Exception in thread Thread-13 (start_client)    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-4-fa427e760366>\", line 73, in start_client\n",
            ":\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "TypeError: start_numpy_client() got an unexpected keyword argument 'stop_event'\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-4-fa427e760366>\", line 73, in start_client\n",
            "TypeError: start_numpy_client() got an unexpected keyword argument 'stop_event'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting clients...\n",
            "Federated learning process completed.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "import warnings\n",
        "from threading import Thread, Event\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Generate dummy dataset\n",
        "def generate_dummy_data(num_samples, num_features):\n",
        "    X = np.random.randn(num_samples, num_features)\n",
        "    y = np.random.randint(0, 2, num_samples)\n",
        "    return X, y\n",
        "\n",
        "# Define Flower client\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = LogisticRegression()\n",
        "        # Initialize the model to ensure consistent shapes\n",
        "        self.model.fit(self.X, self.y)\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [self.model.coef_.astype(np.float32), self.model.intercept_.astype(np.float32)]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        self.model.coef_ = parameters[0].astype(np.float64)\n",
        "        self.model.intercept_ = parameters[1].astype(np.float64)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.fit(self.X, self.y)\n",
        "        return self.get_parameters(config), len(self.X), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        y_pred = self.model.predict_proba(self.X)\n",
        "        loss = log_loss(self.y, y_pred)\n",
        "        accuracy = self.model.score(self.X, self.y)\n",
        "        return loss, len(self.X), {\"accuracy\": accuracy}\n",
        "\n",
        "# Define client function\n",
        "def client_fn(cid: str) -> fl.client.Client:\n",
        "    X, y = generate_dummy_data(100, 4)\n",
        "    return FlowerClient(X, y)\n",
        "\n",
        "# Define strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=1.0,\n",
        "    min_fit_clients=3,\n",
        "    min_evaluate_clients=3,\n",
        "    min_available_clients=3,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(\n",
        "        [np.zeros((1, 4), dtype=np.float32), np.zeros(1, dtype=np.float32)]\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Start Flower server\n",
        "def start_server(stop_event):\n",
        "    fl.server.start_server(\n",
        "        server_address=\"[::]:8084\",\n",
        "        config=fl.server.ServerConfig(num_rounds=3),\n",
        "        strategy=strategy,\n",
        "        stop_event=stop_event\n",
        "    )\n",
        "\n",
        "# Client function\n",
        "def start_client(stop_event):\n",
        "    fl.client.start_numpy_client(server_address=\"[::]:8084\", client=client_fn, root_certificates=None, stop_event=stop_event)\n",
        "\n",
        "# Function to run the server in a separate thread\n",
        "def run_server(stop_event):\n",
        "    server_thread = Thread(target=start_server, args=(stop_event,))\n",
        "    server_thread.start()\n",
        "    return server_thread\n",
        "\n",
        "# Function to run multiple clients\n",
        "def run_clients(num_clients=3, stop_event=None):\n",
        "    client_threads = []\n",
        "    for _ in range(num_clients):\n",
        "        client_thread = Thread(target=start_client, args=(stop_event,))\n",
        "        client_thread.start()\n",
        "        client_threads.append(client_thread)\n",
        "    return client_threads\n",
        "\n",
        "# Main function to run the federated learning process\n",
        "def run_federated_learning():\n",
        "    stop_event = Event()\n",
        "\n",
        "    print(\"Starting server...\")\n",
        "    server_thread = run_server(stop_event)\n",
        "\n",
        "    # Wait for the server to start\n",
        "    time.sleep(5)\n",
        "\n",
        "    print(\"Starting clients...\")\n",
        "    client_threads = run_clients(3, stop_event)\n",
        "\n",
        "    # Wait for all clients to finish\n",
        "    for thread in client_threads:\n",
        "        thread.join()\n",
        "\n",
        "    # Stop the server\n",
        "    stop_event.set()\n",
        "    server_thread.join()\n",
        "\n",
        "    print(\"Federated learning process completed.\")\n",
        "\n",
        "# Run the federated learning process\n",
        "if __name__ == \"__main__\":\n",
        "    run_federated_learning()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a code to configure a federated learning strategy and implement a server that coordinates the federated learning process."
      ],
      "metadata": {
        "id": "2athMArQinYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Define the Flower client\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.model = LogisticRegression()\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [self.model.coef_, self.model.intercept_]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        self.model.coef_ = parameters[0]\n",
        "        self.model.intercept_ = parameters[1]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        self.model.fit(self.X, self.y)\n",
        "        return self.get_parameters(config), len(self.X), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        loss = log_loss(self.y, self.model.predict_proba(self.X))\n",
        "        accuracy = self.model.score(self.X, self.y)\n",
        "        return loss, len(self.X), {\"accuracy\": accuracy}\n",
        "\n",
        "# Define the client function\n",
        "def client_fn(cid: str) -> fl.client.Client:\n",
        "    X, y = generate_dummy_data(100, 4)\n",
        "    return FlowerClient(X, y)\n",
        "\n",
        "# Define the strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=1.0,\n",
        "    min_fit_clients=3,\n",
        "    min_evaluate_clients=3,\n",
        "    min_available_clients=3,\n",
        ")\n",
        "\n",
        "# Define the server configuration\n",
        "server_config = fl.server.ServerConfig(num_rounds=3)\n",
        "\n",
        "# Start the Flower server\n",
        "def start_server():\n",
        "    fl.server.start_server(\n",
        "        server_address=\"[::]:8084\",\n",
        "        config=server_config,\n",
        "        strategy=strategy,\n",
        "    )\n",
        "\n",
        "# Run the server in a separate thread\n",
        "def run_server():\n",
        "    server_thread = Thread(target=start_server)\n",
        "    server_thread.start()\n",
        "    return server_thread\n",
        "\n",
        "# Main function to run the federated learning process\n",
        "def run_federated_learning():\n",
        "    print(\"Starting server...\")\n",
        "    server_thread = run_server()\n",
        "\n",
        "    # Wait for the server to start\n",
        "    time.sleep(5)\n",
        "\n",
        "    print(\"Federated learning process completed.\")\n",
        "\n",
        "# Run the federated learning process\n",
        "run_federated_learning()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLgzCJqWik0W",
        "outputId": "03e36613-e7b1-4f0a-8cc1-5891f7a3fc85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower server, config: num_rounds=3, no round_timeout\n",
            "INFO:flwr:Starting Flower server, config: num_rounds=3, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting server...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
            "INFO:flwr:Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "INFO:flwr:[INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Federated learning process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a code to Implement a federated averaging strategy for model aggregation"
      ],
      "metadata": {
        "id": "boIRqprIi7MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl\n",
        "import numpy as np\n",
        "\n",
        "# Define the federated averaging strategy\n",
        "class CustomFedAvg(fl.server.strategy.FedAvg):\n",
        "    def aggregate_fit(self, server_round, results, failures):\n",
        "        aggregated_weights = super().aggregate_fit(server_round, results, failures)\n",
        "\n",
        "        # You can further customize the aggregation process here\n",
        "        # For example, you can use a weighted average based on the client dataset sizes\n",
        "        # aggregated_weights = self.weighted_average(results)\n",
        "\n",
        "        return aggregated_weights\n",
        "\n",
        "    # def weighted_average(self, results):\n",
        "    #     total_size = sum(result.num_examples for result, _ in results)\n",
        "    #     aggregated_weights = [\n",
        "    #         np.average([result.parameters[i] for result, _ in results], axis=0, weights=[result.num_examples / total_size for result, _ in results])\n",
        "    #         for i in range(len(results[0][0].parameters))\n",
        "    #     ]\n",
        "    #     return aggregated_weights\n",
        "\n",
        "# Define the server configuration\n",
        "server_config = fl.server.ServerConfig(num_rounds=3)\n",
        "\n",
        "# Create the custom strategy instance\n",
        "custom_strategy = CustomFedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=1.0,\n",
        "    min_fit_clients=3,\n",
        "    min_evaluate_clients=3,\n",
        "    min_available_clients=3,\n",
        ")\n",
        "\n",
        "# Start the Flower server with the custom strategy\n",
        "def start_server():\n",
        "    fl.server.start_server(\n",
        "        server_address=\"[::]:8084\",\n",
        "        config=server_config,\n",
        "        strategy=custom_strategy,\n",
        "    )\n",
        "\n",
        "# Run the server in a separate thread\n",
        "def run_server():\n",
        "    server_thread = Thread(target=start_server)\n",
        "    server_thread.start()\n",
        "    return server_thread\n",
        "\n",
        "# Main function to run the federated learning process\n",
        "def run_federated_learning():\n",
        "    print(\"Starting server...\")\n",
        "    server_thread = run_server()\n",
        "\n",
        "    # Wait for the server to start\n",
        "    time.sleep(5)\n",
        "\n",
        "    print(\"Federated learning process completed.\")\n",
        "\n",
        "# Run the federated learning process\n",
        "run_federated_learning()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT5pTXTYip6G",
        "outputId": "ece1079b-08de-470a-e081-719f72c6c33d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower server, config: num_rounds=3, no round_timeout\n",
            "INFO:flwr:Starting Flower server, config: num_rounds=3, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
            "INFO:flwr:Flower ECE: gRPC server running (3 rounds), SSL is disabled\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "INFO:flwr:[INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting server...\n",
            "Federated learning process completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6QiTKBe0jAC2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}